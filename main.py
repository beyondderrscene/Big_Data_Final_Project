import pandas as pd
import numpy as np
from sklearn.preprocessing import PowerTransformer, StandardScaler
from sklearn.mixture import GaussianMixture
import hdbscan

import warnings
warnings.filterwarnings('ignore')

def cluster_with_hdbscan_gmm(input_path, output_path, n_features):
    print(f"Processing: {input_path}")

    # Load and preprocess
    df = pd.read_csv(input_path)
    X = df[[str(i + 1) for i in range(n_features)]].values
    X_powered = PowerTransformer(method='yeo-johnson').fit_transform(X)
    X_std = StandardScaler().fit_transform(X_powered)

    # Try to figure out a rough structure using HDBSCAN
    hdb = hdbscan.HDBSCAN(min_cluster_size=100, min_samples=5)
    _ = hdb.fit_predict(X_std)

    # Use Tied GMM to "force" clusters generated by HDBSCAN into 4n-1 clusters
    n_clusters = 4 * n_features - 1
    gmm = GaussianMixture(
        n_components=n_clusters,
        covariance_type='tied',
        random_state=42,
        max_iter=400,
        n_init=10
    )
    labels = gmm.fit_predict(X_std)

    # Save output
    df["label"] = labels
    df_out = df[["id", "label"]].sort_values("id")
    df_out.to_csv(output_path, index=False)
    print(f"Done: {output_path}, {n_clusters} clusters.")

cluster_with_hdbscan_gmm(
    input_path="public_data.csv",
    output_path="public_submission.csv",
    n_features=4
)

cluster_with_hdbscan_gmm(
    input_path="private_data.csv",
    output_path="private_submission.csv",
    n_features=6
)
